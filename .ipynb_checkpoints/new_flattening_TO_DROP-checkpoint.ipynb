{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsons_as_cols(df, JSON_COLUMNS):\n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasforma liste di dizionari in un solo dizionario\n",
    "def unpack(col):\n",
    "    mod = []\n",
    "    for row in col:\n",
    "        try:\n",
    "            mod += eval(row)\n",
    "        except:\n",
    "            mod += row\n",
    "\n",
    "    return pd.Series(mod)\n",
    "\n",
    "\n",
    "def correction_nan(x):\n",
    "    if type(x) == type(0.0):\n",
    "        return {}\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def mappa(fun, ite):\n",
    "    return [fun(x) for x in ite]\n",
    "\n",
    "\n",
    "# Ã¨ una sola la colonna che ricevo e la trasformo in un dict\n",
    "def from_dict_to_frame(df, col):\n",
    "    # return pd.DataFrame(df[col])\n",
    "\n",
    "    df[col] = mappa(correction_nan, df[col])\n",
    "\n",
    "    new = []\n",
    "    for c in df[col]:\n",
    "        new += [c]\n",
    "    new2 = pd.DataFrame.from_records(new)\n",
    "    # corretto new2 -> print(type(new2))\n",
    "\n",
    "    return new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasforma n colonne con un dict all interno in un dizionario che le comprende\n",
    "def unfold(df, cols,target):\n",
    "    for col in cols:\n",
    "        if col not in target:\n",
    "            df = df.merge(from_dict_to_frame(df, col), right_index=True, left_index=True)\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lists(df,target):\n",
    "    lists_to_dump = []\n",
    "    for x in range(len(df.columns)):\n",
    "        try:\n",
    "            if (type(eval(df.iloc[0, x])) == type([])) & (df.columns[x] not in target):\n",
    "                lists_to_dump += [df.columns[x]]\n",
    "        except:\n",
    "            try:\n",
    "                if (type(df.iloc[0, x]) == type([])) & (df.columns[x] not in target):\n",
    "                    lists_to_dump += [df.columns[x]]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return lists_to_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dicts(df,target):\n",
    "    dicts_to_dump = []\n",
    "    for x in range(len(df.columns)):\n",
    "        try:\n",
    "            if (type(df.iloc[0, x]) == type({})) & (df.columns[x] not in target):\n",
    "                dicts_to_dump += [df.columns[x]]\n",
    "        except:\n",
    "            try:\n",
    "                if (type(eval(df.iloc[0, x])) == type({})) & (df.columns[x] not in target):\n",
    "                    dicts_to_dump += [df.columns[x]]\n",
    "            except:\n",
    "                pass\n",
    "    if \"transactionRevenue\" in dicts_to_dump:\n",
    "        print(\"errore in find_dicts\")\n",
    "    return dicts_to_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_const(df,target):\n",
    "    for col in df.columns:\n",
    "        if (df[col].astype(str).nunique(dropna=False) == 1) & (col not in target):\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(csv_path,n_rows,target):\n",
    "    JSON_COLUMNS = [\"device\", \"geoNetwork\", \"totals\", \"trafficSource\"]\n",
    "\n",
    "    df = pd.read_csv(csv_path,\n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}\n",
    "                     ,nrows = n_rows, dtype={\"fullVisitorId\": \"str\"}\n",
    "                     )\n",
    "    \n",
    "    df = load_jsons_as_cols(df,JSON_COLUMNS)\n",
    "    \n",
    "    #while ((len(find_dicts(df,target)) > 0) | (len(find_lists(df,target)) > 0)):\n",
    "\n",
    "    if len(find_lists(df,target)) > 0:\n",
    "        for col in find_lists(df,target):\n",
    "            df[col] = unpack(df[col])\n",
    "            \n",
    "    while len(find_dicts(df,target)) > 0:\n",
    "        df = unfold(df, find_dicts(df,target),target)\n",
    "        \n",
    "    summa=0\n",
    "    new_col = []\n",
    "    #ciclo le colonne che ho scoperto contenere liste\n",
    "    for col in find_lists(df,target):\n",
    "        #ciclo le righe che contenti liste\n",
    "        for row in df[col]:\n",
    "            #ciclo la lista contenete dizionari\n",
    "            if len(row)>0:\n",
    "                #print(row[:3],len(row))\n",
    "                for d in row:\n",
    "                    try:\n",
    "                        summa += float(d['productPrice'])\n",
    "                    except:\n",
    "                        pass\n",
    "                new_col += [summa]\n",
    "                summa = 0\n",
    "    df[\"transactionRevenue\"] = pd.Series(new_col)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\"fullVisitorId\",\"transactionRevenue\"]\n",
    "train_df = load_df(train_file,10000,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[\"product\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
